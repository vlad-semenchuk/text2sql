name: Claude Code Review

on:
  pull_request:
    types: [ opened, synchronize, ready_for_review, reopened ]

jobs:
  claude-review:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      issues: read
      id-token: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Calculate Metrics
        id: metrics
        run: |
          echo "start_time=$(date -u +%s)" >> $GITHUB_OUTPUT
          echo "pr_size=$(git diff --stat ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} 2>/dev/null | tail -1 | awk '{print $4+$6}' || echo '0')" >> $GITHUB_OUTPUT

      - name: Run Claude Pragmatic Review
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          track_progress: true
          prompt: |
            # PRAGMATIC QUALITY REVIEW
            
            **Context**: ${{ github.repository }} PR #${{ github.event.pull_request.number }} (${{ steps.metrics.outputs.pr_size }} lines)
            
            **Security Note**: Security vulnerabilities are handled by a separate workflow. Focus on architecture, design, quality, testing, and performance.
            
            ---
            
            ## REVIEW STRUCTURE: FECE + MoSCoW
            
            Use this structure for EVERY finding:
            
            ```
            ## Finding: [Title] - [Must/Should/Could Have]
            
            📊 FACT: [Location + specific code pattern observed]
            💬 CONTEXT: [Acknowledge effort, collaborative tone]
            ⚠️ IMPACT: [Rework cost + business/technical risk]
            ✅ FIX: [Specific action + code example + acceptance criteria]
            ```
            
            ---
            
            ## PRIORITIZATION (MoSCoW)
            
            **Must Have** - Blocks merge:
            - Critical bugs (data corruption, incorrect business logic)
            - Bad architecture (violates SOLID, breaks layer separation)
            - Missing tests for critical functionality
            - Performance issues (N+1 queries, missing indexes)
            - Very high complexity (hard to maintain/test)
            
            **Should Have** - Strongly recommend:
            - DRY violations in business/critical code (rework amplifier)
            - High complexity functions (testability risk)
            - High coupling / Low cohesion
            - Missing error handling
            - Test coverage gaps for medium-risk features
            
            **Could Have** - Optional (prefix "Nit:"):
            - Style improvements
            - Minor refactoring opportunities
            - Documentation enhancements
            
            ---
            
            ## CORE PRINCIPLES
            
            **DRY**: Duplicated logic = rework multiplier (if bug found, fix in N places)
            **Complexity**: High nesting/branching = hard to test and maintain
            **Coupling**: Tight dependencies = changes ripple across codebase
            **Testing**: Coverage proportional to risk (critical=must, medium=should, low=could)
            
            ---
            
            ## WORKFLOW
            
            1. **Gather context**:
            ```bash
            gh pr view ${{ github.event.pull_request.number }} --json title,body,files
            gh pr diff ${{ github.event.pull_request.number }}
            cat CLAUDE.md 2>/dev/null || echo "No conventions"
            ```
            
            2. **Assess PR**: Size (<100 small, 100-500 medium, 500-1000 large, >1000 very large), type, risk
            
            3. **Review files**: Check architecture, DRY, complexity, coupling, testing, performance
            
            4. **Generate findings**: Use FECE structure with MoSCoW labels
            
            5. **Summary**:
            ```markdown
            # 🎯 REVIEW SUMMARY
            
            **Decision**: [✅ Approve | 🔄 Request Changes | 💬 Comment]
            **Health**: [Improves ✅ | Neutral ➡️ | Degrades ⚠️]
            **Risk**: [🟢 Low | 🟡 Medium | 🔴 High]
            
            ## Strengths
            - [Good patterns observed]
            
            ## Critical (Must Have) - [N findings]
            [Use FECE structure for each]
            
            ## Recommended (Should Have) - [N findings]
            [Use FECE structure for each]
            
            ## Optional (Could Have) - [N findings]
            - Nit: [Brief description]
            ```
            
            6. **Post review**:
            ```bash
            gh pr comment ${{ github.event.pull_request.number }} --body-file review.md
            # Use inline comments for line-specific feedback
            ```
            
            ---
            
            ## PHILOSOPHY
            
            - **Net Positive > Perfection**: Approve if PR improves codebase health
            - **Block Only Critical**: Must Have = production risk or significant future rework
            - **Empathetic**: Acknowledge effort, provide clear fixes
            - **Pragmatic**: Minimize future maintenance cost
            
            ---
            
            **Self-check**: FECE structure? MoSCoW labels? Tone collaborative? Fixes prescriptive?

          # Syntax validated against anthropics/claude-code-action@v1 documentation
          # Model: claude-sonnet-4-5 (official API identifier uses dashes)
          # --allowedTools uses camelCase (not kebab-case)
          # Reference: https://docs.claude.com/en/docs/about-claude/models
          claude_args: '--model claude-sonnet-4-5 --allowedTools "Read,Glob,Grep,Bash(gh pr:*),Bash(gh issue:*),Bash(gh search:*),Bash(gh api:*),Bash(git diff:*),Bash(git log:*),Bash(git show:*),mcp__github_inline_comment__create_inline_comment"'

      - name: Track Review Metrics
        if: always()
        run: |
          END_TIME=$(date -u +%s)
          LATENCY=$((END_TIME - ${{ steps.metrics.outputs.start_time }}))
          
          echo "Review completed in ${LATENCY}s for ${{ steps.metrics.outputs.pr_size }} lines"
          
          # Optional: Send to your metrics platform
          # curl -X POST ${{ secrets.METRICS_ENDPOINT }} \
          #   -H "Content-Type: application/json" \
          #   -d "{\"repo\":\"${{ github.repository }}\",\"pr\":${{ github.event.pull_request.number }},\"latency\":$LATENCY,\"size\":${{ steps.metrics.outputs.pr_size }}}"
